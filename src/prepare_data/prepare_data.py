# This is a script to generate train/val data for the chat-gpt detector.
import json


def write_to_jsonl_file(file_path, data):
    with open(file_path, "w") as file:
        for item in data:
            json.dump(item, file, ensure_ascii=False)
            file.write("\n")


def generate_train_val(
    real_data_path,
    gpt_data_path,
    output_train_path,
    output_val_path,
    train_size=5000,
    val_size=100,
):
    train_data = []
    val_data = []
    train_index = train_size
    val_index = train_size + val_size
    with open(gpt_data_path, "r") as file:
        gpt_data = json.load(file)

        for index, d in enumerate(gpt_data):
            item = {
                "text": d["output"],
                "label": "fake",
            }
            if index < train_index:
                train_data.append(item)
            elif index < val_index:
                val_data.append(item)
            else:
                break

    count = 0
    with open(real_data_path, "r") as file:
        for line in file:
            try:
                original_item = json.loads(line)
                item = {"text": original_item["text"], "label": "real"}
                if count < train_index:
                    train_data.append(item)
                elif count < val_index:
                    val_data.append(item)
                else:
                    break
                count += 1
            except json.JSONDecodeError:
                # This line is not valid json format, just skip
                pass

    # print out to check data
    print(len(train_data))
    print(train_data[0])
    print(train_data[5000])
    print(len(val_data))
    print(val_data[0])
    print(val_data[100])

    write_to_jsonl_file(output_train_path, train_data)
    write_to_jsonl_file(output_val_path, val_data)


if __name__ == "__main__":
    # The webtext dataset is collected from web, we label them as "real" (human input data)
    real_data_path = "data/webtext.train.jsonl"

    # The alpaca dataset is generated by chat-gpt, we use the "output" field and label them as "fake"
    gpt_data_path = "data/alpaca_data_cleaned_archive.json"

    output_train_path = "data/train.jsonl"
    output_val_path = "data/val.jsonl"

    generate_train_val(
        real_data_path, gpt_data_path, output_train_path, output_val_path
    )
